{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Shape Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_load import ShapeDimensionDataset\n",
    "from regression import Net1, train_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Transforms\n",
    "\n",
    "full_transform = transforms.Compose([\n",
    "    # these operate on PIL image\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # the fill thing needs to be 255 (white); we're still in uint8 mode\n",
    "    transforms.RandomRotation((0,90), expand=True, fill=255),\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])\n",
    "\n",
    "flip_transform = transforms.Compose([\n",
    "    # these operate on PIL image\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])\n",
    "\n",
    "no_transform = transforms.Compose([\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "\n",
    "omit test for the time being ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\"h\", \"tw\", \"ba\", \"ra\"]\n",
    "target_cols = [\"h_scaled\", \"tw_scaled\", \"ba_scaled\", \"ra_scaled\"]\n",
    "\n",
    "datasets = {\n",
    "    'train': ShapeDimensionDataset(\"dataset/L2_train.csv\", \n",
    "                                   \"dataset/train/L2/\",\n",
    "                                   transform=flip_transform, \n",
    "                                   target_cols=target_cols),\n",
    "    'val': ShapeDimensionDataset(\"dataset/L2_val.csv\", \n",
    "                                 \"dataset/val/L2/\",\n",
    "                                 transform=flip_transform, \n",
    "                                 target_cols=target_cols),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloaders = {'train': DataLoader(datasets['train'], \n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=True, \n",
    "                                   num_workers=6),\n",
    "               'val': DataLoader(datasets['val'], \n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False, \n",
    "                                 num_workers=6),                                       \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show something\n",
    "\n",
    "Convert PIL grayscale image (type=L) to np array (axes are still flipped):\n",
    "\n",
    "`img = np.frombuffer(img_.tobytes(), dtype=np.uint8).reshape(224,224)`\n",
    "\n",
    "Convert torch.Tensor to np array:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel value range: 0.0 1.0\n",
      "shape: (100, 100)\n",
      "dtype: float32\n",
      "[[0.85637428]\n",
      " [0.11926557]\n",
      " [0.32567999]\n",
      " [0.2473557 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets['train']\n",
    "\n",
    "img_, y = ds[67]  \n",
    "# TODO: how to rotate ???\n",
    "img = img_[0].numpy() # shape(1,224,224) -> shape(224,224)\n",
    "img = img.squeeze()\n",
    "print(\"pixel value range:\", np.min(img), np.max(img))\n",
    "# TODO: these are grayscale (B/W) pictures. One depth dimension is enough.\n",
    "print(\"shape:\", img.shape)\n",
    "print(\"dtype:\", img.dtype)\n",
    "print(y)\n",
    "plt.imshow(img, cmap='gray');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, log=False):\n",
    "    \"\"\"history plot, return image\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history['train'], \"o-\", label=\"train\")\n",
    "    ax.plot(history['val'], \"o-\", label=\"val\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    if log:\n",
    "        ax.semilogy()\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1936, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0003\n",
    "\n",
    "model = Net1(4, image_size=100, param_names=[\"h\", \"tw\", \"ba\", \"ra\"], description=\"L2\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "print(model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400: train Loss: 0.041981 val Loss: 0.025136 \n",
      "\n",
      "Epoch 2/400: train Loss: 0.017135 val Loss: 0.012154 \n",
      "\n",
      "Epoch 3/400: train Loss: 0.011240 val Loss: 0.009635 \n",
      "\n",
      "Epoch 4/400: train Loss: 0.009119 val Loss: 0.007749 \n",
      "\n",
      "Epoch 5/400: train Loss: 0.006877 val Loss: 0.006014 \n",
      "\n",
      "Epoch 6/400: train Loss: 0.005217 val Loss: 0.004682 \n",
      "\n",
      "Epoch 7/400: train Loss: 0.004085 val Loss: 0.004151 \n",
      "\n",
      "Epoch 8/400: train Loss: 0.003558 val Loss: 0.003495 \n",
      "\n",
      "Epoch 9/400: train Loss: 0.003098 val Loss: 0.003006 \n",
      "\n",
      "Epoch 10/400: train Loss: 0.003087 val Loss: 0.002817 \n",
      "\n",
      "Epoch 11/400: train Loss: 0.002526 val Loss: 0.002566 \n",
      "\n",
      "Epoch 12/400: train Loss: 0.002458 val Loss: 0.002373 \n",
      "\n",
      "Epoch 13/400: train Loss: 0.002254 val Loss: 0.002876 \n",
      "\n",
      "Epoch 14/400: train Loss: 0.002160 val Loss: 0.001920 \n",
      "\n",
      "Epoch 15/400: train Loss: 0.001801 val Loss: 0.001674 \n",
      "\n",
      "Epoch 16/400: train Loss: 0.001774 val Loss: 0.001765 \n",
      "\n",
      "Epoch 17/400: train Loss: 0.001577 val Loss: 0.001606 \n",
      "\n",
      "Epoch 18/400: train Loss: 0.001523 val Loss: 0.001503 \n",
      "\n",
      "Epoch 19/400: train Loss: 0.001413 val Loss: 0.001209 \n",
      "\n",
      "Epoch 20/400: train Loss: 0.001264 val Loss: 0.001357 \n",
      "\n",
      "Epoch 21/400: train Loss: 0.001250 val Loss: 0.001231 \n",
      "\n",
      "Epoch 22/400: train Loss: 0.001213 val Loss: 0.001193 \n",
      "\n",
      "Epoch 23/400: train Loss: 0.001158 val Loss: 0.001041 \n",
      "\n",
      "Epoch 24/400: train Loss: 0.001147 val Loss: 0.001149 \n",
      "\n",
      "Epoch 25/400: train Loss: 0.001069 val Loss: 0.001015 \n",
      "\n",
      "Epoch 26/400: train Loss: 0.001104 val Loss: 0.001692 \n",
      "\n",
      "Epoch 27/400: train Loss: 0.001025 val Loss: 0.000862 \n",
      "\n",
      "Epoch 28/400: train Loss: 0.000936 val Loss: 0.000972 \n",
      "\n",
      "Epoch 29/400: train Loss: 0.000980 val Loss: 0.000803 \n",
      "\n",
      "Epoch 30/400: train Loss: 0.000893 val Loss: 0.000847 \n",
      "\n",
      "Epoch 31/400: train Loss: 0.000973 val Loss: 0.001126 \n",
      "\n",
      "Epoch 32/400: train Loss: 0.000849 val Loss: 0.000773 \n",
      "\n",
      "Epoch 33/400: train Loss: 0.000923 val Loss: 0.000792 \n",
      "\n",
      "Epoch 34/400: train Loss: 0.000805 val Loss: 0.001043 \n",
      "\n",
      "Epoch 35/400: train Loss: 0.000810 val Loss: 0.000890 \n",
      "\n",
      "Epoch 36/400: train Loss: 0.000762 val Loss: 0.000934 \n",
      "\n",
      "Epoch 37/400: train Loss: 0.000820 val Loss: 0.001074 \n",
      "\n",
      "Epoch 38/400: train Loss: 0.000787 val Loss: 0.000739 \n",
      "\n",
      "Epoch 39/400: train Loss: 0.000803 val Loss: 0.000748 \n",
      "\n",
      "Epoch 40/400: train Loss: 0.000715 val Loss: 0.000825 \n",
      "\n",
      "Epoch 41/400: train Loss: 0.000657 val Loss: 0.000699 \n",
      "\n",
      "Epoch 42/400: train Loss: 0.000676 val Loss: 0.000900 \n",
      "\n",
      "Epoch 43/400: train Loss: 0.000696 val Loss: 0.000727 \n",
      "\n",
      "Epoch 44/400: train Loss: 0.000622 val Loss: 0.000642 \n",
      "\n",
      "Epoch 45/400: train Loss: 0.000638 val Loss: 0.000679 \n",
      "\n",
      "Epoch 46/400: train Loss: 0.000619 val Loss: 0.000598 \n",
      "\n",
      "Epoch 47/400: train Loss: 0.000597 val Loss: 0.000615 \n",
      "\n",
      "Epoch 48/400: train Loss: 0.000633 val Loss: 0.000616 \n",
      "\n",
      "Epoch 49/400: train Loss: 0.000600 val Loss: 0.000596 \n",
      "\n",
      "Epoch 50/400: train Loss: 0.000589 val Loss: 0.000591 \n",
      "\n",
      "Epoch 51/400: train Loss: 0.000591 val Loss: 0.000590 \n",
      "\n",
      "Epoch 52/400: train Loss: 0.000529 val Loss: 0.000819 \n",
      "\n",
      "Epoch 53/400: train Loss: 0.000566 val Loss: 0.000604 \n",
      "\n",
      "Epoch 54/400: train Loss: 0.000538 val Loss: 0.000598 \n",
      "\n",
      "Epoch 55/400: train Loss: 0.000592 val Loss: 0.000523 \n",
      "\n",
      "Epoch 56/400: train Loss: 0.000532 val Loss: 0.000526 \n",
      "\n",
      "Epoch 57/400: train Loss: 0.000535 val Loss: 0.000523 \n",
      "\n",
      "Epoch 58/400: train Loss: 0.000542 val Loss: 0.000629 \n",
      "\n",
      "Epoch 59/400: train Loss: 0.000498 val Loss: 0.000595 \n",
      "\n",
      "Epoch 60/400: train Loss: 0.000517 val Loss: 0.000535 \n",
      "\n",
      "Epoch 61/400: train Loss: 0.000475 val Loss: 0.000457 \n",
      "\n",
      "Epoch 62/400: train Loss: 0.000469 val Loss: 0.000682 \n",
      "\n",
      "Epoch 63/400: train Loss: 0.000482 val Loss: 0.000756 \n",
      "\n",
      "Epoch 64/400: train Loss: 0.000500 val Loss: 0.000458 \n",
      "\n",
      "Epoch 65/400: train Loss: 0.000445 val Loss: 0.000512 \n",
      "\n",
      "Epoch 66/400: train Loss: 0.000472 val Loss: 0.000477 \n",
      "\n",
      "Epoch 67/400: train Loss: 0.000490 val Loss: 0.000623 \n",
      "\n",
      "Epoch 68/400: train Loss: 0.000436 val Loss: 0.000506 \n",
      "\n",
      "Epoch 69/400: train Loss: 0.000437 val Loss: 0.000525 \n",
      "\n",
      "Epoch 70/400: train Loss: 0.000423 val Loss: 0.000488 \n",
      "\n",
      "Epoch 71/400: train Loss: 0.000410 val Loss: 0.000431 \n",
      "\n",
      "Epoch 72/400: train Loss: 0.000433 val Loss: 0.000762 \n",
      "\n",
      "Epoch 73/400: train Loss: 0.000505 val Loss: 0.000657 \n",
      "\n",
      "Epoch 74/400: train Loss: 0.000407 val Loss: 0.000379 \n",
      "\n",
      "Epoch 75/400: train Loss: 0.000438 val Loss: 0.000440 \n",
      "\n",
      "Epoch 76/400: train Loss: 0.000416 val Loss: 0.000528 \n",
      "\n",
      "Epoch 77/400: train Loss: 0.000425 val Loss: 0.000460 \n",
      "\n",
      "Epoch 78/400: train Loss: 0.000416 val Loss: 0.000368 \n",
      "\n",
      "Epoch 79/400: train Loss: 0.000439 val Loss: 0.000426 \n",
      "\n",
      "Epoch 80/400: train Loss: 0.000388 val Loss: 0.000521 \n",
      "\n",
      "Epoch 81/400: train Loss: 0.000457 val Loss: 0.000422 \n",
      "\n",
      "Epoch 82/400: train Loss: 0.000363 val Loss: 0.000442 \n",
      "\n",
      "Epoch 83/400: train Loss: 0.000352 val Loss: 0.000481 \n",
      "\n",
      "Epoch 84/400: train Loss: 0.000380 val Loss: 0.000355 \n",
      "\n",
      "Epoch 85/400: train Loss: 0.000397 val Loss: 0.000436 \n",
      "\n",
      "Epoch 86/400: train Loss: 0.000348 val Loss: 0.000357 \n",
      "\n",
      "Epoch 87/400: train Loss: 0.000384 val Loss: 0.000426 \n",
      "\n",
      "Epoch 88/400: train Loss: 0.000364 val Loss: 0.000347 \n",
      "\n",
      "Epoch 89/400: train Loss: 0.000399 val Loss: 0.000427 \n",
      "\n",
      "Epoch 90/400: train Loss: 0.000340 val Loss: 0.000475 \n",
      "\n",
      "Epoch 91/400: train Loss: 0.000376 val Loss: 0.000427 \n",
      "\n",
      "Epoch 92/400: train Loss: 0.000330 val Loss: 0.000382 \n",
      "\n",
      "Epoch 93/400: train Loss: 0.000359 val Loss: 0.000429 \n",
      "\n",
      "Epoch 94/400: train Loss: 0.000342 val Loss: 0.000520 \n",
      "\n",
      "Epoch 95/400: train Loss: 0.000392 val Loss: 0.000428 \n",
      "\n",
      "Epoch 96/400: train Loss: 0.000372 val Loss: 0.000455 \n",
      "\n",
      "Epoch 97/400: train Loss: 0.000323 val Loss: 0.000339 \n",
      "\n",
      "Epoch 98/400: train Loss: 0.000307 val Loss: 0.000408 \n",
      "\n",
      "Epoch 99/400: train Loss: 0.000320 val Loss: 0.000339 \n",
      "\n",
      "Epoch 100/400: train Loss: 0.000311 val Loss: 0.000394 \n",
      "\n",
      "Epoch 101/400: train Loss: 0.000335 val Loss: 0.000488 \n",
      "\n",
      "Epoch 102/400: train Loss: 0.000313 val Loss: 0.000464 \n",
      "\n",
      "Epoch 103/400: train Loss: 0.000343 val Loss: 0.000335 \n",
      "\n",
      "Epoch 104/400: train Loss: 0.000310 val Loss: 0.000337 \n",
      "\n",
      "Epoch 105/400: train Loss: 0.000333 val Loss: 0.000301 \n",
      "\n",
      "Epoch 106/400: train Loss: 0.000308 val Loss: 0.000315 \n",
      "\n",
      "Epoch 107/400: train Loss: 0.000297 val Loss: 0.000377 \n",
      "\n",
      "Epoch 108/400: train Loss: 0.000318 val Loss: 0.000450 \n",
      "\n",
      "Epoch 109/400: train Loss: 0.000306 val Loss: 0.000309 \n",
      "\n",
      "Epoch 110/400: train Loss: 0.000302 val Loss: 0.000332 \n",
      "\n",
      "Epoch 111/400: train Loss: 0.000300 val Loss: 0.000291 \n",
      "\n",
      "Epoch 112/400: train Loss: 0.000287 val Loss: 0.000379 \n",
      "\n",
      "Epoch 113/400: train Loss: 0.000293 val Loss: 0.000399 \n",
      "\n",
      "Epoch 114/400: train Loss: 0.000296 val Loss: 0.000271 \n",
      "\n",
      "Epoch 115/400: train Loss: 0.000269 val Loss: 0.000311 \n",
      "\n",
      "Epoch 116/400: train Loss: 0.000270 val Loss: 0.000368 \n",
      "\n",
      "Epoch 117/400: train Loss: 0.000320 val Loss: 0.000320 \n",
      "\n",
      "Epoch 118/400: train Loss: 0.000280 val Loss: 0.000398 \n",
      "\n",
      "Epoch 119/400: train Loss: 0.000279 val Loss: 0.000327 \n",
      "\n",
      "Epoch 120/400: train Loss: 0.000258 val Loss: 0.000348 \n",
      "\n",
      "Epoch 121/400: train Loss: 0.000286 val Loss: 0.000313 \n",
      "\n",
      "Epoch 122/400: train Loss: 0.000286 val Loss: 0.000300 \n",
      "\n",
      "Epoch 123/400: train Loss: 0.000291 val Loss: 0.000474 \n",
      "\n",
      "Epoch 124/400: train Loss: 0.000360 val Loss: 0.000321 \n",
      "\n",
      "Epoch 125/400: train Loss: 0.000291 val Loss: 0.000345 \n",
      "\n",
      "Epoch 126/400: train Loss: 0.000277 val Loss: 0.000371 \n",
      "\n",
      "Epoch 127/400: train Loss: 0.000286 val Loss: 0.000270 \n",
      "\n",
      "Epoch 128/400: train Loss: 0.000251 val Loss: 0.000268 \n",
      "\n",
      "Epoch 129/400: train Loss: 0.000238 val Loss: 0.000372 \n",
      "\n",
      "Epoch 130/400: train Loss: 0.000287 val Loss: 0.000301 \n",
      "\n",
      "Epoch 131/400: train Loss: 0.000242 val Loss: 0.000325 \n",
      "\n",
      "Epoch 132/400: train Loss: 0.000283 val Loss: 0.000270 \n",
      "\n",
      "Epoch 133/400: train Loss: 0.000266 val Loss: 0.000287 \n",
      "\n",
      "Epoch 134/400: train Loss: 0.000242 val Loss: 0.000265 \n",
      "\n",
      "Epoch 135/400: train Loss: 0.000237 val Loss: 0.000338 \n",
      "\n",
      "Epoch 136/400: train Loss: 0.000228 val Loss: 0.000282 \n",
      "\n",
      "Epoch 137/400: train Loss: 0.000226 val Loss: 0.000362 \n",
      "\n",
      "Epoch 138/400: train Loss: 0.000253 val Loss: 0.000256 \n",
      "\n",
      "Epoch 139/400: train Loss: 0.000237 val Loss: 0.000323 \n",
      "\n",
      "Epoch 140/400: train Loss: 0.000276 val Loss: 0.000283 \n",
      "\n",
      "Epoch 141/400: train Loss: 0.000236 val Loss: 0.000319 \n",
      "\n",
      "Epoch 142/400: train Loss: 0.000252 val Loss: 0.000252 \n",
      "\n",
      "Epoch 143/400: train Loss: 0.000219 val Loss: 0.000243 \n",
      "\n",
      "Epoch 144/400: train Loss: 0.000231 val Loss: 0.000284 \n",
      "\n",
      "Epoch 145/400: train Loss: 0.000222 val Loss: 0.000244 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/400: train Loss: 0.000240 val Loss: 0.000305 \n",
      "\n",
      "Epoch 147/400: train Loss: 0.000252 val Loss: 0.000274 \n",
      "\n",
      "Epoch 148/400: train Loss: 0.000224 val Loss: 0.000301 \n",
      "\n",
      "Epoch 149/400: train Loss: 0.000238 val Loss: 0.000276 \n",
      "\n",
      "Epoch 150/400: train Loss: 0.000248 val Loss: 0.000270 \n",
      "\n",
      "Epoch 151/400: train Loss: 0.000220 val Loss: 0.000287 \n",
      "\n",
      "Epoch 152/400: train Loss: 0.000224 val Loss: 0.000275 \n",
      "\n",
      "Epoch 153/400: train Loss: 0.000212 val Loss: 0.000240 \n",
      "\n",
      "Epoch 154/400: train Loss: 0.000251 val Loss: 0.000324 \n",
      "\n",
      "Epoch 155/400: train Loss: 0.000233 val Loss: 0.000281 \n",
      "\n",
      "Epoch 156/400: train Loss: 0.000226 val Loss: 0.000256 \n",
      "\n",
      "Epoch 157/400: train Loss: 0.000207 val Loss: 0.000294 \n",
      "\n",
      "Epoch 158/400: train Loss: 0.000205 val Loss: 0.000287 \n",
      "\n",
      "Epoch 159/400: train Loss: 0.000227 val Loss: 0.000273 \n",
      "\n",
      "Epoch 160/400: train Loss: 0.000190 val Loss: 0.000225 \n",
      "\n",
      "Epoch 161/400: train Loss: 0.000220 val Loss: 0.000249 \n",
      "\n",
      "Epoch 162/400: train Loss: 0.000220 val Loss: 0.000281 \n",
      "\n",
      "Epoch 163/400: train Loss: 0.000204 val Loss: 0.000249 \n",
      "\n",
      "Epoch 164/400: train Loss: 0.000212 val Loss: 0.000280 \n",
      "\n",
      "Epoch 165/400: train Loss: 0.000214 val Loss: 0.000229 \n",
      "\n",
      "Epoch 166/400: train Loss: 0.000194 val Loss: 0.000241 \n",
      "\n",
      "Epoch 167/400: train Loss: 0.000179 val Loss: 0.000208 \n",
      "\n",
      "Epoch 168/400: train Loss: 0.000203 val Loss: 0.000238 \n",
      "\n",
      "Epoch 169/400: train Loss: 0.000184 val Loss: 0.000240 \n",
      "\n",
      "Epoch 170/400: train Loss: 0.000202 val Loss: 0.000384 \n",
      "\n",
      "Epoch 171/400: train Loss: 0.000229 val Loss: 0.000236 \n",
      "\n",
      "Epoch 172/400: train Loss: 0.000186 val Loss: 0.000265 \n",
      "\n",
      "Epoch 173/400: train Loss: 0.000192 val Loss: 0.000235 \n",
      "\n",
      "Epoch 174/400: train Loss: 0.000204 val Loss: 0.000269 \n",
      "\n",
      "Epoch 175/400: train Loss: 0.000192 val Loss: 0.000296 \n",
      "\n",
      "Epoch 176/400: train Loss: 0.000241 val Loss: 0.000257 \n",
      "\n",
      "Epoch 177/400: train Loss: 0.000210 val Loss: 0.000316 \n",
      "\n",
      "Epoch 178/400: train Loss: 0.000205 val Loss: 0.000221 \n",
      "\n",
      "Epoch 179/400: train Loss: 0.000177 val Loss: 0.000225 \n",
      "\n",
      "Epoch 180/400: train Loss: 0.000183 val Loss: 0.000280 \n",
      "\n",
      "Epoch 181/400: train Loss: 0.000199 val Loss: 0.000241 \n",
      "\n",
      "Epoch 182/400: train Loss: 0.000195 val Loss: 0.000275 \n",
      "\n",
      "Epoch 183/400: train Loss: 0.000210 val Loss: 0.000201 \n",
      "\n",
      "Epoch 184/400: train Loss: 0.000173 val Loss: 0.000211 \n",
      "\n",
      "Epoch 185/400: train Loss: 0.000171 val Loss: 0.000248 \n",
      "\n",
      "Epoch 186/400: train Loss: 0.000194 val Loss: 0.000238 \n",
      "\n",
      "Epoch 187/400: train Loss: 0.000167 val Loss: 0.000210 \n",
      "\n",
      "Epoch 188/400: train Loss: 0.000187 val Loss: 0.000213 \n",
      "\n",
      "Epoch 189/400: train Loss: 0.000187 val Loss: 0.000201 \n",
      "\n",
      "Epoch 190/400: train Loss: 0.000176 val Loss: 0.000206 \n",
      "\n",
      "Epoch 191/400: train Loss: 0.000166 val Loss: 0.000217 \n",
      "\n",
      "Epoch 192/400: train Loss: 0.000178 val Loss: 0.000204 \n",
      "\n",
      "Epoch 193/400: train Loss: 0.000199 val Loss: 0.000225 \n",
      "\n",
      "Epoch 194/400: train Loss: 0.000180 val Loss: 0.000264 \n",
      "\n",
      "Epoch 195/400: train Loss: 0.000165 val Loss: 0.000233 \n",
      "\n",
      "Epoch 196/400: train Loss: 0.000164 val Loss: 0.000222 \n",
      "\n",
      "Epoch 197/400: train Loss: 0.000197 val Loss: 0.000242 \n",
      "\n",
      "Epoch 198/400: train Loss: 0.000168 val Loss: 0.000171 \n",
      "\n",
      "Epoch 199/400: train Loss: 0.000171 val Loss: 0.000210 \n",
      "\n",
      "Epoch 200/400: train Loss: 0.000152 val Loss: 0.000206 \n",
      "\n",
      "Epoch 201/400: train Loss: 0.000180 val Loss: 0.000252 \n",
      "\n",
      "Epoch 202/400: train Loss: 0.000166 val Loss: 0.000202 \n",
      "\n",
      "Epoch 203/400: train Loss: 0.000188 val Loss: 0.000193 \n",
      "\n",
      "Epoch 204/400: train Loss: 0.000163 val Loss: 0.000190 \n",
      "\n",
      "Epoch 205/400: train Loss: 0.000180 val Loss: 0.000223 \n",
      "\n",
      "Epoch 206/400: train Loss: 0.000161 val Loss: 0.000178 \n",
      "\n",
      "Epoch 207/400: train Loss: 0.000174 val Loss: 0.000214 \n",
      "\n",
      "Epoch 208/400: train Loss: 0.000156 val Loss: 0.000218 \n",
      "\n",
      "Epoch 209/400: train Loss: 0.000154 val Loss: 0.000225 \n",
      "\n",
      "Epoch 210/400: train Loss: 0.000159 val Loss: 0.000219 \n",
      "\n",
      "Epoch 211/400: train Loss: 0.000156 val Loss: 0.000329 \n",
      "\n",
      "Epoch 212/400: train Loss: 0.000158 val Loss: 0.000207 \n",
      "\n",
      "Epoch 213/400: train Loss: 0.000175 val Loss: 0.000196 \n",
      "\n",
      "Epoch 214/400: train Loss: 0.000155 val Loss: 0.000190 \n",
      "\n",
      "Epoch 215/400: train Loss: 0.000140 val Loss: 0.000179 \n",
      "\n",
      "Epoch 216/400: train Loss: 0.000161 val Loss: 0.000196 \n",
      "\n",
      "Epoch 217/400: train Loss: 0.000163 val Loss: 0.000204 \n",
      "\n",
      "Epoch 218/400: train Loss: 0.000160 val Loss: 0.000223 \n",
      "\n",
      "Epoch 219/400: train Loss: 0.000177 val Loss: 0.000240 \n",
      "\n",
      "Epoch 220/400: train Loss: 0.000161 val Loss: 0.000265 \n",
      "\n",
      "Epoch 221/400: train Loss: 0.000167 val Loss: 0.000197 \n",
      "\n",
      "Epoch 222/400: train Loss: 0.000163 val Loss: 0.000199 \n",
      "\n",
      "Epoch 223/400: train Loss: 0.000155 val Loss: 0.000187 \n",
      "\n",
      "Epoch 224/400: train Loss: 0.000157 val Loss: 0.000196 \n",
      "\n",
      "Epoch 225/400: train Loss: 0.000158 val Loss: 0.000208 \n",
      "\n",
      "Epoch 226/400: train Loss: 0.000149 val Loss: 0.000187 \n",
      "\n",
      "Epoch 227/400: train Loss: 0.000150 val Loss: 0.000241 \n",
      "\n",
      "Epoch 228/400: train Loss: 0.000162 val Loss: 0.000222 \n",
      "\n",
      "Epoch 229/400: train Loss: 0.000149 val Loss: 0.000212 \n",
      "\n",
      "Epoch 230/400: train Loss: 0.000137 val Loss: 0.000237 \n",
      "\n",
      "Epoch 231/400: train Loss: 0.000142 val Loss: 0.000208 \n",
      "\n",
      "Epoch 232/400: train Loss: 0.000138 val Loss: 0.000208 \n",
      "\n",
      "Epoch 233/400: train Loss: 0.000140 val Loss: 0.000174 \n",
      "\n",
      "Epoch 234/400: train Loss: 0.000143 val Loss: 0.000192 \n",
      "\n",
      "Epoch 235/400: train Loss: 0.000149 val Loss: 0.000194 \n",
      "\n",
      "Epoch 236/400: train Loss: 0.000164 val Loss: 0.000194 \n",
      "\n",
      "Epoch 237/400: train Loss: 0.000151 val Loss: 0.000208 \n",
      "\n",
      "Epoch 238/400: train Loss: 0.000137 val Loss: 0.000198 \n",
      "\n",
      "Epoch 239/400: train Loss: 0.000139 val Loss: 0.000178 \n",
      "\n",
      "Epoch 240/400: train Loss: 0.000152 val Loss: 0.000198 \n",
      "\n",
      "Epoch 241/400: train Loss: 0.000153 val Loss: 0.000291 \n",
      "\n",
      "Epoch 242/400: train Loss: 0.000157 val Loss: 0.000217 \n",
      "\n",
      "Epoch 243/400: train Loss: 0.000142 val Loss: 0.000197 \n",
      "\n",
      "Epoch 244/400: train Loss: 0.000135 val Loss: 0.000190 \n",
      "\n",
      "Epoch 245/400: train Loss: 0.000145 val Loss: 0.000169 \n",
      "\n",
      "Epoch 246/400: train Loss: 0.000146 val Loss: 0.000207 \n",
      "\n",
      "Epoch 247/400: train Loss: 0.000137 val Loss: 0.000292 \n",
      "\n",
      "Epoch 248/400: train Loss: 0.000161 val Loss: 0.000178 \n",
      "\n",
      "Epoch 249/400: train Loss: 0.000130 val Loss: 0.000192 \n",
      "\n",
      "Epoch 250/400: train Loss: 0.000133 val Loss: 0.000182 \n",
      "\n",
      "Epoch 251/400: train Loss: 0.000138 val Loss: 0.000202 \n",
      "\n",
      "Epoch 252/400: train Loss: 0.000158 val Loss: 0.000229 \n",
      "\n",
      "Epoch 253/400: train Loss: 0.000159 val Loss: 0.000183 \n",
      "\n",
      "Epoch 254/400: train Loss: 0.000126 val Loss: 0.000224 \n",
      "\n",
      "Epoch 255/400: train Loss: 0.000135 val Loss: 0.000153 \n",
      "\n",
      "Epoch 256/400: train Loss: 0.000127 val Loss: 0.000180 \n",
      "\n",
      "Epoch 257/400: train Loss: 0.000136 val Loss: 0.000190 \n",
      "\n",
      "Epoch 258/400: train Loss: 0.000130 val Loss: 0.000171 \n",
      "\n",
      "Epoch 259/400: train Loss: 0.000144 val Loss: 0.000198 \n",
      "\n",
      "Epoch 260/400: train Loss: 0.000133 val Loss: 0.000170 \n",
      "\n",
      "Epoch 261/400: train Loss: 0.000133 val Loss: 0.000158 \n",
      "\n",
      "Epoch 262/400: train Loss: 0.000141 val Loss: 0.000210 \n",
      "\n",
      "Epoch 263/400: train Loss: 0.000128 val Loss: 0.000194 \n",
      "\n",
      "Epoch 264/400: train Loss: 0.000142 val Loss: 0.000180 \n",
      "\n",
      "Epoch 265/400: train Loss: 0.000143 val Loss: 0.000160 \n",
      "\n",
      "Epoch 266/400: train Loss: 0.000120 val Loss: 0.000191 \n",
      "\n",
      "Epoch 267/400: train Loss: 0.000137 val Loss: 0.000179 \n",
      "\n",
      "Epoch 268/400: train Loss: 0.000110 val Loss: 0.000161 \n",
      "\n",
      "Epoch 269/400: train Loss: 0.000121 val Loss: 0.000155 \n",
      "\n",
      "Epoch 270/400: train Loss: 0.000120 val Loss: 0.000209 \n",
      "\n",
      "Epoch 271/400: train Loss: 0.000138 val Loss: 0.000178 \n",
      "\n",
      "Epoch 272/400: train Loss: 0.000128 val Loss: 0.000172 \n",
      "\n",
      "Epoch 273/400: train Loss: 0.000128 val Loss: 0.000196 \n",
      "\n",
      "Epoch 274/400: train Loss: 0.000123 val Loss: 0.000174 \n",
      "\n",
      "Epoch 275/400: train Loss: 0.000127 val Loss: 0.000193 \n",
      "\n",
      "Epoch 276/400: train Loss: 0.000133 val Loss: 0.000231 \n",
      "\n",
      "Epoch 277/400: train Loss: 0.000138 val Loss: 0.000165 \n",
      "\n",
      "Epoch 278/400: train Loss: 0.000128 val Loss: 0.000172 \n",
      "\n",
      "Epoch 279/400: train Loss: 0.000130 val Loss: 0.000204 \n",
      "\n",
      "Epoch 280/400: train Loss: 0.000113 val Loss: 0.000193 \n",
      "\n",
      "Epoch 281/400: train Loss: 0.000122 val Loss: 0.000161 \n",
      "\n",
      "Epoch 282/400: train Loss: 0.000121 val Loss: 0.000144 \n",
      "\n",
      "Epoch 283/400: train Loss: 0.000113 val Loss: 0.000181 \n",
      "\n",
      "Epoch 284/400: train Loss: 0.000113 val Loss: 0.000194 \n",
      "\n",
      "Epoch 285/400: train Loss: 0.000125 val Loss: 0.000144 \n",
      "\n",
      "Epoch 286/400: train Loss: 0.000109 val Loss: 0.000158 \n",
      "\n",
      "Epoch 287/400: train Loss: 0.000114 val Loss: 0.000149 \n",
      "\n",
      "Epoch 288/400: train Loss: 0.000118 val Loss: 0.000214 \n",
      "\n",
      "Epoch 289/400: train Loss: 0.000127 val Loss: 0.000161 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/400: train Loss: 0.000113 val Loss: 0.000171 \n",
      "\n",
      "Epoch 291/400: train Loss: 0.000123 val Loss: 0.000167 \n",
      "\n",
      "Epoch 292/400: train Loss: 0.000122 val Loss: 0.000154 \n",
      "\n",
      "Epoch 293/400: train Loss: 0.000121 val Loss: 0.000182 \n",
      "\n",
      "Epoch 294/400: train Loss: 0.000118 val Loss: 0.000174 \n",
      "\n",
      "Epoch 295/400: train Loss: 0.000106 val Loss: 0.000184 \n",
      "\n",
      "Epoch 296/400: train Loss: 0.000108 val Loss: 0.000176 \n",
      "\n",
      "Epoch 297/400: train Loss: 0.000117 val Loss: 0.000165 \n",
      "\n",
      "Epoch 298/400: train Loss: 0.000113 val Loss: 0.000166 \n",
      "\n",
      "Epoch 299/400: train Loss: 0.000115 val Loss: 0.000162 \n",
      "\n",
      "Epoch 300/400: train Loss: 0.000112 val Loss: 0.000161 \n",
      "\n",
      "Epoch 301/400: train Loss: 0.000120 val Loss: 0.000170 \n",
      "\n",
      "Epoch 302/400: train Loss: 0.000127 val Loss: 0.000160 \n",
      "\n",
      "Epoch 303/400: train Loss: 0.000105 val Loss: 0.000159 \n",
      "\n",
      "Epoch 304/400: train Loss: 0.000118 val Loss: 0.000157 \n",
      "\n",
      "Epoch 305/400: train Loss: 0.000118 val Loss: 0.000181 \n",
      "\n",
      "Epoch 306/400: train Loss: 0.000117 val Loss: 0.000184 \n",
      "\n",
      "Epoch 307/400: train Loss: 0.000106 val Loss: 0.000164 \n",
      "\n",
      "Epoch 308/400: train Loss: 0.000117 val Loss: 0.000154 \n",
      "\n",
      "Epoch 309/400: train Loss: 0.000125 val Loss: 0.000147 \n",
      "\n",
      "Epoch 310/400: train Loss: 0.000102 val Loss: 0.000188 \n",
      "\n",
      "Epoch 311/400: train Loss: 0.000116 val Loss: 0.000216 \n",
      "\n",
      "Epoch 312/400: train Loss: 0.000109 val Loss: 0.000162 \n",
      "\n",
      "Epoch 313/400: train Loss: 0.000119 val Loss: 0.000181 \n",
      "\n",
      "Epoch 314/400: train Loss: 0.000115 val Loss: 0.000190 \n",
      "\n",
      "Epoch 315/400: train Loss: 0.000109 val Loss: 0.000135 \n",
      "\n",
      "Epoch 316/400: train Loss: 0.000104 val Loss: 0.000176 \n",
      "\n",
      "Epoch 317/400: train Loss: 0.000112 val Loss: 0.000159 \n",
      "\n",
      "Epoch 318/400: train Loss: 0.000105 val Loss: 0.000150 \n",
      "\n",
      "Epoch 319/400: train Loss: 0.000107 val Loss: 0.000164 \n",
      "\n",
      "Epoch 320/400: train Loss: 0.000099 val Loss: 0.000185 \n",
      "\n",
      "Epoch 321/400: train Loss: 0.000106 val Loss: 0.000191 \n",
      "\n",
      "Epoch 322/400: train Loss: 0.000109 val Loss: 0.000163 \n",
      "\n",
      "Epoch 323/400: train Loss: 0.000094 val Loss: 0.000185 \n",
      "\n",
      "Epoch 324/400: train Loss: 0.000109 val Loss: 0.000169 \n",
      "\n",
      "Epoch 325/400: train Loss: 0.000106 val Loss: 0.000157 \n",
      "\n",
      "Epoch 326/400: train Loss: 0.000115 val Loss: 0.000171 \n",
      "\n",
      "Epoch 327/400: train Loss: 0.000120 val Loss: 0.000183 \n",
      "\n",
      "Epoch 328/400: train Loss: 0.000116 val Loss: 0.000186 \n",
      "\n",
      "Epoch 329/400: train Loss: 0.000102 val Loss: 0.000131 \n",
      "\n",
      "Epoch 330/400: train Loss: 0.000099 val Loss: 0.000175 \n",
      "\n",
      "Epoch 331/400: train Loss: 0.000103 val Loss: 0.000166 \n",
      "\n",
      "Epoch 332/400: train Loss: 0.000102 val Loss: 0.000171 \n",
      "\n",
      "Epoch 333/400: train Loss: 0.000109 val Loss: 0.000151 \n",
      "\n",
      "Epoch 334/400: train Loss: 0.000102 val Loss: 0.000157 \n",
      "\n",
      "Epoch 335/400: train Loss: 0.000106 val Loss: 0.000145 \n",
      "\n",
      "Epoch 336/400: train Loss: 0.000112 val Loss: 0.000184 \n",
      "\n",
      "Epoch 337/400: train Loss: 0.000101 val Loss: 0.000191 \n",
      "\n",
      "Epoch 338/400: train Loss: 0.000096 val Loss: 0.000126 \n",
      "\n",
      "Epoch 339/400: train Loss: 0.000104 val Loss: 0.000187 \n",
      "\n",
      "Epoch 340/400: train Loss: 0.000097 val Loss: 0.000151 \n",
      "\n",
      "Epoch 341/400: train Loss: 0.000104 val Loss: 0.000167 \n",
      "\n",
      "Epoch 342/400: train Loss: 0.000103 val Loss: 0.000195 \n",
      "\n",
      "Epoch 343/400: train Loss: 0.000099 val Loss: 0.000170 \n",
      "\n",
      "Epoch 344/400: train Loss: 0.000112 val Loss: 0.000169 \n",
      "\n",
      "Epoch 345/400: train Loss: 0.000103 val Loss: 0.000144 \n",
      "\n",
      "Epoch 346/400: train Loss: 0.000102 val Loss: 0.000166 \n",
      "\n",
      "Epoch 347/400: train Loss: 0.000092 val Loss: 0.000141 \n",
      "\n",
      "Epoch 348/400: train Loss: 0.000090 val Loss: 0.000208 \n",
      "\n",
      "Epoch 349/400: train Loss: 0.000110 val Loss: 0.000164 \n",
      "\n",
      "Epoch 350/400: train Loss: 0.000093 val Loss: 0.000157 \n",
      "\n",
      "Epoch 351/400: train Loss: 0.000097 val Loss: 0.000155 \n",
      "\n",
      "Epoch 352/400: train Loss: 0.000094 val Loss: 0.000149 \n",
      "\n",
      "Epoch 353/400: train Loss: 0.000095 val Loss: 0.000146 \n",
      "\n",
      "Epoch 354/400: train Loss: 0.000092 val Loss: 0.000198 \n",
      "\n",
      "Epoch 355/400: train Loss: 0.000106 val Loss: 0.000173 \n",
      "\n",
      "Epoch 356/400: train Loss: 0.000095 val Loss: 0.000143 \n",
      "\n",
      "Epoch 357/400: train Loss: 0.000098 val Loss: 0.000159 \n",
      "\n",
      "Epoch 358/400: train Loss: 0.000094 val Loss: 0.000146 \n",
      "\n",
      "Epoch 359/400: train Loss: 0.000101 val Loss: 0.000167 \n",
      "\n",
      "Epoch 360/400: train Loss: 0.000096 val Loss: 0.000196 \n",
      "\n",
      "Epoch 361/400: train Loss: 0.000094 val Loss: 0.000143 \n",
      "\n",
      "Epoch 362/400: train Loss: 0.000092 val Loss: 0.000146 \n",
      "\n",
      "Epoch 363/400: train Loss: 0.000092 val Loss: 0.000153 \n",
      "\n",
      "Epoch 364/400: train Loss: 0.000092 val Loss: 0.000126 \n",
      "\n",
      "Epoch 365/400: train Loss: 0.000092 val Loss: 0.000180 \n",
      "\n",
      "Epoch 366/400: train Loss: 0.000096 val Loss: 0.000160 \n",
      "\n",
      "Epoch 367/400: train Loss: 0.000098 val Loss: 0.000136 \n",
      "\n",
      "Epoch 368/400: train Loss: 0.000085 val Loss: 0.000159 \n",
      "\n",
      "Epoch 369/400: train Loss: 0.000099 val Loss: 0.000161 \n",
      "\n",
      "Epoch 370/400: train Loss: 0.000098 val Loss: 0.000147 \n",
      "\n",
      "Epoch 371/400: train Loss: 0.000078 val Loss: 0.000145 \n",
      "\n",
      "Epoch 372/400: train Loss: 0.000098 val Loss: 0.000147 \n",
      "\n",
      "Epoch 373/400: train Loss: 0.000089 val Loss: 0.000142 \n",
      "\n",
      "Epoch 374/400: train Loss: 0.000093 val Loss: 0.000151 \n",
      "\n",
      "Epoch 375/400: train Loss: 0.000107 val Loss: 0.000168 \n",
      "\n",
      "Epoch 376/400: train Loss: 0.000094 val Loss: 0.000138 \n",
      "\n",
      "Epoch 377/400: train Loss: 0.000099 val Loss: 0.000152 \n",
      "\n",
      "Epoch 378/400: train Loss: 0.000087 val Loss: 0.000155 \n",
      "\n",
      "Epoch 379/400: train Loss: 0.000093 val Loss: 0.000150 \n",
      "\n",
      "Epoch 380/400: train Loss: 0.000081 val Loss: 0.000133 \n",
      "\n",
      "Epoch 381/400: train Loss: 0.000084 val Loss: 0.000139 \n",
      "\n",
      "Epoch 382/400: train Loss: 0.000098 val Loss: 0.000149 \n",
      "\n",
      "Epoch 383/400: train Loss: 0.000089 val Loss: 0.000158 \n",
      "\n",
      "Epoch 384/400: train Loss: 0.000086 val Loss: 0.000153 \n",
      "\n",
      "Epoch 385/400: train Loss: 0.000098 val Loss: 0.000133 \n",
      "\n",
      "Epoch 386/400: train Loss: 0.000084 val Loss: 0.000145 \n",
      "\n",
      "Epoch 387/400: train Loss: 0.000089 val Loss: 0.000154 \n",
      "\n",
      "Epoch 388/400: train Loss: 0.000093 val Loss: 0.000141 \n",
      "\n",
      "Epoch 389/400: train Loss: 0.000089 val Loss: 0.000143 \n",
      "\n",
      "Epoch 390/400: train Loss: 0.000079 val Loss: 0.000146 \n",
      "\n",
      "Epoch 391/400: train Loss: 0.000080 val Loss: 0.000139 \n",
      "\n",
      "Epoch 392/400: train Loss: 0.000082 val Loss: 0.000154 \n",
      "\n",
      "Epoch 393/400: train Loss: 0.000087 val Loss: 0.000134 \n",
      "\n",
      "Epoch 394/400: train Loss: 0.000082 val Loss: 0.000137 \n",
      "\n",
      "Epoch 395/400: train Loss: 0.000086 val Loss: 0.000176 \n",
      "\n",
      "Epoch 396/400: train Loss: 0.000089 val Loss: 0.000136 \n",
      "\n",
      "Epoch 397/400: train Loss: 0.000097 val Loss: 0.000169 \n",
      "\n",
      "Epoch 398/400: train Loss: 0.000086 val Loss: 0.000133 \n",
      "\n",
      "Epoch 399/400: train Loss: 0.000095 val Loss: 0.000149 \n",
      "\n",
      "Epoch 400/400: train Loss: 0.000093 val Loss: 0.000188 \n",
      "\n",
      "\n",
      "Best val loss: 0.000126\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    hist = train_regression(model, dataloaders, criterion, optimizer, num_epochs=400)\n",
    "    plot_history(hist, log=True)\n",
    "    model.save_checkpoint(\"models/L2_Net1_400_flip.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, great! It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sections import VERTEX_FUNCTIONS\n",
    "\n",
    "l2_func, l2_params = VERTEX_FUNCTIONS['l2']\n",
    "\n",
    "def imshow(tensor):\n",
    "    \"\"\"show first image in a tensor\"\"\"\n",
    "    img = tensor[0].numpy() # shape(1,224,224) -> shape(224,224)\n",
    "    img = img.squeeze()\n",
    "    plt.imshow(img, cmap='gray');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2\n",
      "Input size: 100, output size: 4\n",
      "parameter names: h, tw, ba, ra\n"
     ]
    }
   ],
   "source": [
    "model = Net1.from_checkpoint(\"models/L2_Net1_400_flip.pt\")\n",
    "\n",
    "# scaler\n",
    "with open(\"dataset/L2_scaler.pkl\", \"rb\") as fp:\n",
    "    scaler = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 67\n",
    "area = 200\n",
    "\n",
    "# get data point\n",
    "ds = datasets['val']\n",
    "image, target = ds[i]\n",
    "# show image and target\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 100, 100])\n",
      "torch.float32\n",
      "tensor(1.)\n",
      "['h', 'tw', 'ba', 'ra']\n",
      "target (scaled):  [0.18140609 0.71524415 0.1976198  0.71125736]\n",
      "output (scaled):  [0.18314792 0.7010044  0.20056257 0.7353648 ]\n",
      "target (unscaled):  [62.82134859  2.51285394 24.50032595 10.67962926]\n",
      "output (unscaled):  [62.984318   2.4829128 24.776804  10.972761 ]\n"
     ]
    }
   ],
   "source": [
    "img = image.reshape(1, 1, 100, 100)\n",
    "print(img.shape)\n",
    "print(img.dtype)\n",
    "print(img.max())\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    outputs = model.forward(img)\n",
    "    outputs = outputs.numpy()\n",
    "    \n",
    "# print raw target / output\n",
    "print(l2_params)\n",
    "\n",
    "print(\"target (scaled): \", target.squeeze())\n",
    "print(\"output (scaled): \", outputs.squeeze())\n",
    "\n",
    "# unscale both, multiply with reference length (sqrt(A))\n",
    "target_dim = np.sqrt(area) * scaler.inverse_transform(target.T)\n",
    "target_dim = target_dim.squeeze()\n",
    "output_dim = np.sqrt(area) * scaler.inverse_transform(outputs)\n",
    "output_dim = output_dim.squeeze()\n",
    "print(\"target (unscaled): \", target_dim)\n",
    "print(\"output (unscaled): \", output_dim)\n",
    "\n",
    "# generate vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>tw</th>\n",
       "      <th>ba</th>\n",
       "      <th>ra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>62.82</td>\n",
       "      <td>2.51</td>\n",
       "      <td>24.50</td>\n",
       "      <td>10.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td>62.98</td>\n",
       "      <td>2.48</td>\n",
       "      <td>24.78</td>\n",
       "      <td>10.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h    tw     ba     ra\n",
       "true       62.82  2.51  24.50  10.68\n",
       "predicted  62.98  2.48  24.78  10.97"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show results\n",
    "df = pd.DataFrame([target_dim, output_dim], index=['true', 'predicted'], \n",
    "                  columns=l2_params)\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# generate polygons\n",
    "true_o, true_i = l2_func(*target_dim.squeeze())\n",
    "pred_o, pred_i = l2_func(*output_dim.squeeze())\n",
    "\n",
    "\n",
    "for outer in true_o:\n",
    "    mppoly = plt.Polygon(outer, ec=\"k\", ls='--', fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "for inner in true_i:\n",
    "    mppoly = plt.Polygon(inner, ec=\"k\", ls='--', fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "    \n",
    "for outer in pred_o:\n",
    "    mppoly = plt.Polygon(outer, ec=\"r\", fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "for inner in pred_i:\n",
    "    mppoly = plt.Polygon(inner, ec=\"r\", fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "\n",
    "ax.autoscale(tight=False)\n",
    "ax.set_aspect(\"equal\")\n",
    "#ax.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate: Compute IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Loop: Input polygon vertices, create image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
