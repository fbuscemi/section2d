{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Shape Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_load import ShapeDimensionDataset\n",
    "\n",
    "from sections import VERTEX_FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Transforms\n",
    "\n",
    "full_transform = transforms.Compose([\n",
    "    # these operate on PIL image\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # the fill thing needs to be 255 (white); we're still in uint8 mode\n",
    "    transforms.RandomRotation((0,90), expand=True, fill=255),\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])\n",
    "\n",
    "flip_transform = transforms.Compose([\n",
    "    # these operate on PIL image\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])\n",
    "\n",
    "no_transform = transforms.Compose([\n",
    "    # Normalise wants a tensor as input, so ToTensor has to run first\n",
    "    transforms.Resize((100, 100), interpolation=0),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(0, 1), \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Dataloaders\n",
    "\n",
    "omit test for the time being ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_func, shape_params = VERTEX_FUNCTIONS['i1']\n",
    "target_cols = [p + \"_scaled\" for p in shape_params]\n",
    "\n",
    "datasets = {\n",
    "    'train': ShapeDimensionDataset(\"dataset/I1_train.csv\", \n",
    "                                   \"dataset/train/I1/\",\n",
    "                                   transform=full_transform, \n",
    "                                   target_cols=target_cols\n",
    "                                  ),\n",
    "    'val': ShapeDimensionDataset(\"dataset/I1_val.csv\", \n",
    "                                   \"dataset/val/I1/\",\n",
    "                                   transform=full_transform,\n",
    "                                   target_cols=target_cols\n",
    "                                ),    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "dataloaders = {'train': DataLoader(datasets['train'], \n",
    "                                   batch_size=BATCH_SIZE,\n",
    "                                   shuffle=True, \n",
    "                                   num_workers=6),\n",
    "               'val': DataLoader(datasets['val'], \n",
    "                                 batch_size=BATCH_SIZE,\n",
    "                                 shuffle=False, \n",
    "                                 num_workers=6),                                       \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show something\n",
    "\n",
    "Convert PIL grayscale image (type=L) to np array (axes are still flipped):\n",
    "\n",
    "`img = np.frombuffer(img_.tobytes(), dtype=np.uint8).reshape(224,224)`\n",
    "\n",
    "Convert torch.Tensor to np array:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel value range: 0.0 1.0\n",
      "shape: (100, 100)\n",
      "dtype: float32\n",
      "[[0.50681731]\n",
      " [0.12999685]\n",
      " [0.45390167]\n",
      " [0.05367205]\n",
      " [0.25067951]\n",
      " [0.67717222]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = datasets['train']\n",
    "\n",
    "img_, y = ds[21]  \n",
    "# TODO: how to rotate ???\n",
    "img = img_[0].numpy() # shape(1,224,224) -> shape(224,224)\n",
    "img = img.squeeze()\n",
    "print(\"pixel value range:\", np.min(img), np.max(img))\n",
    "# TODO: these are grayscale (B/W) pictures. One depth dimension is enough.\n",
    "print(\"shape:\", img.shape)\n",
    "print(\"dtype:\", img.dtype)\n",
    "print(y)\n",
    "plt.imshow(img, cmap='gray');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make nicer progress reporting using tqdm\n",
    "# for i, batch in enumerate(tqdm(dataloader))\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler=None, num_epochs=1):\n",
    "    \"\"\"Train a model. After training, the model weights are set to those that resulted \n",
    "    in the lowest validation loss during training.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: a model instance\n",
    "    - dataloaders: a dictionary. Must have keys \"train\" and \"val\", and dataloaders as values\n",
    "    - criterion: a loss function\n",
    "    - optimizer: an optimizer instance\n",
    "    - scheduler: a method from torch.optim.lr_scheduler\n",
    "    - num_epochs: number of epochs to train (default 1)\n",
    "    \n",
    "    Returns:\n",
    "    - history: dict with training/validation loss history\n",
    "    \"\"\"\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # set initial loss to infinity\n",
    "    best_loss = np.inf \n",
    "\n",
    "    dataset_sizes = {k: len(loader.dataset) for k, loader in dataloaders.items()}\n",
    "\n",
    "    # initialise \n",
    "    history = {'train': [], 'val': []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data batches\n",
    "            dataloader = dataloaders[phase]\n",
    "            for batch_i, data in enumerate(dataloader):\n",
    "\n",
    "                # get the input images and the shape parameters\n",
    "                images, targets = data\n",
    "\n",
    "                # flatten pts\n",
    "                targets = targets.view(targets.size(0), -1)\n",
    "\n",
    "                # convert variables to floats for regression loss\n",
    "                #images = images.type(torch.FloatTensor)\n",
    "                targets = targets.type(torch.FloatTensor)\n",
    "\n",
    "                # zero the parameter (weight) gradients\n",
    "                optimizer.zero_grad()                \n",
    "                \n",
    "                # forward pass to get outputs\n",
    "                output = model.forward(images)\n",
    "\n",
    "                # calculate the loss between predicted and target keypoints\n",
    "                loss = criterion(output, targets)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Statistics. Loss function returns mean loss over images; multiply by size of current batch\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # learning rate scheduler\n",
    "            if phase == 'train' and scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            # epoch finished\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            history[phase].append(epoch_loss)\n",
    "            print('{} Loss: {:.6f}'.format(phase, epoch_loss))\n",
    "          \n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # final message\n",
    "    print('\\nBest val loss: {:6f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def conv_dims(input_size, k, s, p):\n",
    "    \"\"\"Return output size for a 2D convolution kernel (square input, \n",
    "    square kernel). See https://arxiv.org/pdf/1603.07285v2.pdf, relationship 6\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : int\n",
    "        size (width) of input feature\n",
    "    k : int\n",
    "        convolution kernel size\n",
    "    s : int\n",
    "        convolution stride\n",
    "    p : int \n",
    "        zero padding\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_size : int\n",
    "        size (width) of output feature\n",
    "    \n",
    "    \"\"\"\n",
    "    return (input_size + 2*p - k)//s + 1\n",
    "\n",
    "\n",
    "\n",
    "def pool_dims(input_size, k, s):\n",
    "    \"\"\"Return output size for a 2D convolution kernel (square input, \n",
    "    square kernel). See https://arxiv.org/pdf/1603.07285v2.pdf, relationship 7\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : int\n",
    "        size (width) of input feature\n",
    "    k : int\n",
    "        pooling kernel size\n",
    "    s : int\n",
    "        pooling stride\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    output_size : int\n",
    "        size (width) of output feature\n",
    "    \n",
    "    \"\"\"\n",
    "    return (input_size - k)//s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 100\n",
    "OUTPUT_SIZE = len(shape_params)\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        # first convolution\n",
    "        i1, m1, n1 = IMAGE_SIZE, 1, 8    # input size, num features in, num out\n",
    "        k1, s1, p1 = 5, 2, 0              # kernel size, stride, padding\n",
    "        o1 = conv_dims(i1, k1, s1, p1)    # output size\n",
    "        # first pooling\n",
    "        kp1, sp1 = 2, 2                   # kernel size, stride  \n",
    "        op1 = pool_dims(o1, kp1, sp1)     # output size\n",
    "        # second convolution\n",
    "        i2, m2, n2 = op1, n1, 16          # input size, num features in, num out\n",
    "        k2, s2, p2 = 3, 1, 0              # kernel size, stride, padding\n",
    "        o2 = conv_dims(i2, k2, s2, p2)    # output size\n",
    "        # second pooling\n",
    "        kp2, sp2 = 2, 2                   # kernel size, stride\n",
    "        op2 = pool_dims(o2, kp2, sp2)     # output size\n",
    "\n",
    "        # fully connected layers\n",
    "        self.mh0 = n2 * op2**2            # needed later - size of first linear layer\n",
    "        mh1 = 1000                        # input size of second fully connected layer        \n",
    "        mh2 = 50                        # input size of second fully connected layer        \n",
    "        \n",
    "        self.conv1 = nn.Conv2d(m1, n1, k1, stride=s1, padding=p1)\n",
    "        self.conv2 = nn.Conv2d(m2, n2, k2, stride=s2, padding=p2)\n",
    "        self.pool1 = nn.MaxPool2d(kp1, stride=sp1)\n",
    "        self.pool2 = nn.MaxPool2d(kp2, stride=sp2)        \n",
    "\n",
    "        self.fc1 = nn.Linear(self.mh0, mh1)\n",
    "        self.fc2 = nn.Linear(mh1, mh2)\n",
    "        self.fc3 = nn.Linear(mh2, OUTPUT_SIZE)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, self.mh0)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, log=False):\n",
    "    \"\"\"history plot, return image\"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(history['train'], \"o-\", label=\"train\")\n",
    "    ax.plot(history['val'], \"o-\", label=\"val\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    if log:\n",
    "        ax.semilogy()\n",
    "    ax.grid()\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1936, out_features=1000, bias=True)\n",
      "  (fc2): Linear(in_features=1000, out_features=50, bias=True)\n",
      "  (fc3): Linear(in_features=50, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lr = 0.0003\n",
    "\n",
    "model = Net1()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "print(model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "----------\n",
      "train Loss: 0.019671\n",
      "val Loss: 0.011228\n",
      "Epoch 2/100\n",
      "----------\n",
      "train Loss: 0.009462\n",
      "val Loss: 0.008225\n",
      "Epoch 3/100\n",
      "----------\n",
      "train Loss: 0.007822\n",
      "val Loss: 0.006959\n",
      "Epoch 4/100\n",
      "----------\n",
      "train Loss: 0.006962\n",
      "val Loss: 0.006141\n",
      "Epoch 5/100\n",
      "----------\n",
      "train Loss: 0.005964\n",
      "val Loss: 0.005758\n",
      "Epoch 6/100\n",
      "----------\n",
      "train Loss: 0.005189\n",
      "val Loss: 0.004655\n",
      "Epoch 7/100\n",
      "----------\n",
      "train Loss: 0.004713\n",
      "val Loss: 0.004257\n",
      "Epoch 8/100\n",
      "----------\n",
      "train Loss: 0.004260\n",
      "val Loss: 0.004023\n",
      "Epoch 9/100\n",
      "----------\n",
      "train Loss: 0.003777\n",
      "val Loss: 0.003391\n",
      "Epoch 10/100\n",
      "----------\n",
      "train Loss: 0.003305\n",
      "val Loss: 0.002975\n",
      "Epoch 11/100\n",
      "----------\n",
      "train Loss: 0.002950\n",
      "val Loss: 0.002976\n",
      "Epoch 12/100\n",
      "----------\n",
      "train Loss: 0.002824\n",
      "val Loss: 0.002481\n",
      "Epoch 13/100\n",
      "----------\n",
      "train Loss: 0.002496\n",
      "val Loss: 0.002740\n",
      "Epoch 14/100\n",
      "----------\n",
      "train Loss: 0.002373\n",
      "val Loss: 0.002287\n",
      "Epoch 15/100\n",
      "----------\n",
      "train Loss: 0.002274\n",
      "val Loss: 0.002062\n",
      "Epoch 16/100\n",
      "----------\n",
      "train Loss: 0.002136\n",
      "val Loss: 0.001954\n",
      "Epoch 17/100\n",
      "----------\n",
      "train Loss: 0.002019\n",
      "val Loss: 0.001932\n",
      "Epoch 18/100\n",
      "----------\n",
      "train Loss: 0.001967\n",
      "val Loss: 0.001983\n",
      "Epoch 19/100\n",
      "----------\n",
      "train Loss: 0.001871\n",
      "val Loss: 0.001712\n",
      "Epoch 20/100\n",
      "----------\n",
      "train Loss: 0.001804\n",
      "val Loss: 0.001804\n",
      "Epoch 21/100\n",
      "----------\n",
      "train Loss: 0.001715\n",
      "val Loss: 0.001787\n",
      "Epoch 22/100\n",
      "----------\n",
      "train Loss: 0.001674\n",
      "val Loss: 0.001743\n",
      "Epoch 23/100\n",
      "----------\n",
      "train Loss: 0.001654\n",
      "val Loss: 0.001700\n",
      "Epoch 24/100\n",
      "----------\n",
      "train Loss: 0.001540\n",
      "val Loss: 0.001750\n",
      "Epoch 25/100\n",
      "----------\n",
      "train Loss: 0.001519\n",
      "val Loss: 0.001505\n",
      "Epoch 26/100\n",
      "----------\n",
      "train Loss: 0.001496\n",
      "val Loss: 0.001522\n",
      "Epoch 27/100\n",
      "----------\n",
      "train Loss: 0.001406\n",
      "val Loss: 0.001501\n",
      "Epoch 28/100\n",
      "----------\n",
      "train Loss: 0.001382\n",
      "val Loss: 0.001547\n",
      "Epoch 29/100\n",
      "----------\n",
      "train Loss: 0.001360\n",
      "val Loss: 0.001400\n",
      "Epoch 30/100\n",
      "----------\n",
      "train Loss: 0.001306\n",
      "val Loss: 0.001407\n",
      "Epoch 31/100\n",
      "----------\n",
      "train Loss: 0.001255\n",
      "val Loss: 0.001225\n",
      "Epoch 32/100\n",
      "----------\n",
      "train Loss: 0.001270\n",
      "val Loss: 0.001272\n",
      "Epoch 33/100\n",
      "----------\n",
      "train Loss: 0.001260\n",
      "val Loss: 0.001215\n",
      "Epoch 34/100\n",
      "----------\n",
      "train Loss: 0.001192\n",
      "val Loss: 0.001303\n",
      "Epoch 35/100\n",
      "----------\n",
      "train Loss: 0.001188\n",
      "val Loss: 0.001325\n",
      "Epoch 36/100\n",
      "----------\n",
      "train Loss: 0.001157\n",
      "val Loss: 0.001198\n",
      "Epoch 37/100\n",
      "----------\n",
      "train Loss: 0.001156\n",
      "val Loss: 0.001214\n",
      "Epoch 38/100\n",
      "----------\n",
      "train Loss: 0.001100\n",
      "val Loss: 0.001185\n",
      "Epoch 39/100\n",
      "----------\n",
      "train Loss: 0.001068\n",
      "val Loss: 0.001254\n",
      "Epoch 40/100\n",
      "----------\n",
      "train Loss: 0.001038\n",
      "val Loss: 0.001096\n",
      "Epoch 41/100\n",
      "----------\n",
      "train Loss: 0.001040\n",
      "val Loss: 0.001126\n",
      "Epoch 42/100\n",
      "----------\n",
      "train Loss: 0.001084\n",
      "val Loss: 0.001199\n",
      "Epoch 43/100\n",
      "----------\n",
      "train Loss: 0.001032\n",
      "val Loss: 0.001000\n",
      "Epoch 44/100\n",
      "----------\n",
      "train Loss: 0.001079\n",
      "val Loss: 0.001010\n",
      "Epoch 45/100\n",
      "----------\n",
      "train Loss: 0.000979\n",
      "val Loss: 0.000972\n",
      "Epoch 46/100\n",
      "----------\n",
      "train Loss: 0.000985\n",
      "val Loss: 0.001161\n",
      "Epoch 47/100\n",
      "----------\n",
      "train Loss: 0.000968\n",
      "val Loss: 0.000975\n",
      "Epoch 48/100\n",
      "----------\n",
      "train Loss: 0.000960\n",
      "val Loss: 0.001069\n",
      "Epoch 49/100\n",
      "----------\n",
      "train Loss: 0.000980\n",
      "val Loss: 0.001002\n",
      "Epoch 50/100\n",
      "----------\n",
      "train Loss: 0.000946\n",
      "val Loss: 0.000979\n",
      "Epoch 51/100\n",
      "----------\n",
      "train Loss: 0.000948\n",
      "val Loss: 0.001037\n",
      "Epoch 52/100\n",
      "----------\n",
      "train Loss: 0.000919\n",
      "val Loss: 0.000880\n",
      "Epoch 53/100\n",
      "----------\n",
      "train Loss: 0.000880\n",
      "val Loss: 0.000904\n",
      "Epoch 54/100\n",
      "----------\n",
      "train Loss: 0.000833\n",
      "val Loss: 0.000953\n",
      "Epoch 55/100\n",
      "----------\n",
      "train Loss: 0.000853\n",
      "val Loss: 0.001024\n",
      "Epoch 56/100\n",
      "----------\n",
      "train Loss: 0.000884\n",
      "val Loss: 0.000805\n",
      "Epoch 57/100\n",
      "----------\n",
      "train Loss: 0.000903\n",
      "val Loss: 0.000876\n",
      "Epoch 58/100\n",
      "----------\n",
      "train Loss: 0.000886\n",
      "val Loss: 0.001039\n",
      "Epoch 59/100\n",
      "----------\n",
      "train Loss: 0.000845\n",
      "val Loss: 0.000999\n",
      "Epoch 60/100\n",
      "----------\n",
      "train Loss: 0.000890\n",
      "val Loss: 0.000909\n",
      "Epoch 61/100\n",
      "----------\n",
      "train Loss: 0.000796\n",
      "val Loss: 0.000862\n",
      "Epoch 62/100\n",
      "----------\n",
      "train Loss: 0.000848\n",
      "val Loss: 0.000925\n",
      "Epoch 63/100\n",
      "----------\n",
      "train Loss: 0.000847\n",
      "val Loss: 0.000942\n",
      "Epoch 64/100\n",
      "----------\n",
      "train Loss: 0.000820\n",
      "val Loss: 0.001049\n",
      "Epoch 65/100\n",
      "----------\n",
      "train Loss: 0.000815\n",
      "val Loss: 0.000956\n",
      "Epoch 66/100\n",
      "----------\n",
      "train Loss: 0.000794\n",
      "val Loss: 0.000833\n",
      "Epoch 67/100\n",
      "----------\n",
      "train Loss: 0.000808\n",
      "val Loss: 0.000907\n",
      "Epoch 68/100\n",
      "----------\n",
      "train Loss: 0.000771\n",
      "val Loss: 0.000879\n",
      "Epoch 69/100\n",
      "----------\n",
      "train Loss: 0.000771\n",
      "val Loss: 0.000883\n",
      "Epoch 70/100\n",
      "----------\n",
      "train Loss: 0.000795\n",
      "val Loss: 0.000825\n",
      "Epoch 71/100\n",
      "----------\n",
      "train Loss: 0.000730\n",
      "val Loss: 0.000828\n",
      "Epoch 72/100\n",
      "----------\n",
      "train Loss: 0.000786\n",
      "val Loss: 0.000818\n",
      "Epoch 73/100\n",
      "----------\n",
      "train Loss: 0.000773\n",
      "val Loss: 0.000809\n",
      "Epoch 74/100\n",
      "----------\n",
      "train Loss: 0.000774\n",
      "val Loss: 0.000864\n",
      "Epoch 75/100\n",
      "----------\n",
      "train Loss: 0.000741\n",
      "val Loss: 0.000811\n",
      "Epoch 76/100\n",
      "----------\n",
      "train Loss: 0.000697\n",
      "val Loss: 0.000831\n",
      "Epoch 77/100\n",
      "----------\n",
      "train Loss: 0.000719\n",
      "val Loss: 0.000852\n",
      "Epoch 78/100\n",
      "----------\n",
      "train Loss: 0.000778\n",
      "val Loss: 0.000843\n",
      "Epoch 79/100\n",
      "----------\n",
      "train Loss: 0.000723\n",
      "val Loss: 0.000718\n",
      "Epoch 80/100\n",
      "----------\n",
      "train Loss: 0.000759\n",
      "val Loss: 0.000907\n",
      "Epoch 81/100\n",
      "----------\n",
      "train Loss: 0.000677\n",
      "val Loss: 0.000783\n",
      "Epoch 82/100\n",
      "----------\n",
      "train Loss: 0.000686\n",
      "val Loss: 0.000802\n",
      "Epoch 83/100\n",
      "----------\n",
      "train Loss: 0.000712\n",
      "val Loss: 0.000713\n",
      "Epoch 84/100\n",
      "----------\n",
      "train Loss: 0.000700\n",
      "val Loss: 0.000750\n",
      "Epoch 85/100\n",
      "----------\n",
      "train Loss: 0.000701\n",
      "val Loss: 0.000731\n",
      "Epoch 86/100\n",
      "----------\n",
      "train Loss: 0.000708\n",
      "val Loss: 0.000808\n",
      "Epoch 87/100\n",
      "----------\n",
      "train Loss: 0.000731\n",
      "val Loss: 0.000772\n",
      "Epoch 88/100\n",
      "----------\n",
      "train Loss: 0.000638\n",
      "val Loss: 0.000797\n",
      "Epoch 89/100\n",
      "----------\n",
      "train Loss: 0.000679\n",
      "val Loss: 0.000791\n",
      "Epoch 90/100\n",
      "----------\n",
      "train Loss: 0.000738\n",
      "val Loss: 0.000794\n",
      "Epoch 91/100\n",
      "----------\n",
      "train Loss: 0.000698\n",
      "val Loss: 0.000770\n",
      "Epoch 92/100\n",
      "----------\n",
      "train Loss: 0.000649\n",
      "val Loss: 0.000799\n",
      "Epoch 93/100\n",
      "----------\n",
      "train Loss: 0.000714\n",
      "val Loss: 0.000836\n",
      "Epoch 94/100\n",
      "----------\n",
      "train Loss: 0.000600\n",
      "val Loss: 0.000801\n",
      "Epoch 95/100\n",
      "----------\n",
      "train Loss: 0.000695\n",
      "val Loss: 0.000846\n",
      "Epoch 96/100\n",
      "----------\n",
      "train Loss: 0.000613\n",
      "val Loss: 0.000678\n",
      "Epoch 97/100\n",
      "----------\n",
      "train Loss: 0.000625\n",
      "val Loss: 0.000710\n",
      "Epoch 98/100\n",
      "----------\n",
      "train Loss: 0.000676\n",
      "val Loss: 0.000761\n",
      "Epoch 99/100\n",
      "----------\n",
      "train Loss: 0.000662\n",
      "val Loss: 0.000696\n",
      "Epoch 100/100\n",
      "----------\n",
      "train Loss: 0.000660\n",
      "val Loss: 0.000579\n",
      "\n",
      "Best val loss: 0.000579\n"
     ]
    }
   ],
   "source": [
    "if 1 == 1:\n",
    "    hist = train_model(model, dataloaders, criterion, optimizer, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(hist, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah, great! It works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training, save your model parameters in the dir 'saved_models'\n",
    "torch.save(model.state_dict(), \"models/I1_Net1_rot_100.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sections import VERTEX_FUNCTIONS\n",
    "\n",
    "shape_func, shape_params = VERTEX_FUNCTIONS['i1']\n",
    "\n",
    "def imshow(tensor):\n",
    "    \"\"\"show first image in a tensor\"\"\"\n",
    "    img = tensor[0].numpy() # shape(1,224,224) -> shape(224,224)\n",
    "    img = img.squeeze()\n",
    "    plt.imshow(img, cmap='gray');\n",
    "    \n",
    "def load_checkpoint(model, fpath):\n",
    "    state_dict = torch.load(fpath, map_location='cpu')\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model, load weights\n",
    "model = Net1()\n",
    "load_checkpoint(model, \"models/I1_Net1_rot_100.pt\")\n",
    "\n",
    "# scaler\n",
    "with open(\"dataset/I1_scaler.pkl\", \"rb\") as fp:\n",
    "    scaler = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 919\n",
    "area = 200\n",
    "\n",
    "# get data point\n",
    "ds = datasets['val']\n",
    "image, target = ds[i]\n",
    "# show image and target\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'tw', 'ba', 'ta', 'bf', 'tf']\n",
      "target (scaled):  [0.75451566 0.20097666 0.69063005 0.09411337 0.07899557 0.29042973]\n",
      "output (scaled):  [[0.7354036  0.1966753  0.6645697  0.09562207 0.10020003 0.17097424]]\n",
      "target (unscaled):  [44.64418717  2.62612866 28.88741523  2.62612866  5.25225731  5.25225731]\n",
      "output (unscaled):  [43.934578   2.5933452 28.002771   2.6463103  5.891225   3.6542983]\n"
     ]
    }
   ],
   "source": [
    "img = image.reshape(1, 1, 100, 100)\n",
    "img.shape\n",
    "with torch.no_grad():\n",
    "    outputs = model.forward(img)\n",
    "    outputs = outputs.numpy()\n",
    "    \n",
    "# print raw target / output\n",
    "print(shape_params)\n",
    "\n",
    "print(\"target (scaled): \", target.squeeze())\n",
    "print(\"output (scaled): \", outputs) #.squeeze())\n",
    "\n",
    "# unscale both, multiply with reference length (sqrt(A))\n",
    "target_dim = np.sqrt(area) * scaler.inverse_transform(target.T)\n",
    "target_dim = target_dim.squeeze()\n",
    "output_dim = np.sqrt(area) * scaler.inverse_transform(outputs)\n",
    "output_dim = output_dim.squeeze()\n",
    "print(\"target (unscaled): \", target_dim)\n",
    "print(\"output (unscaled): \", output_dim)\n",
    "\n",
    "# generate vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h</th>\n",
       "      <th>tw</th>\n",
       "      <th>ba</th>\n",
       "      <th>ta</th>\n",
       "      <th>bf</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true</th>\n",
       "      <td>44.64</td>\n",
       "      <td>2.63</td>\n",
       "      <td>28.89</td>\n",
       "      <td>2.63</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <td>43.93</td>\n",
       "      <td>2.59</td>\n",
       "      <td>28.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>5.89</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h    tw     ba    ta    bf    tf\n",
       "true       44.64  2.63  28.89  2.63  5.25  5.25\n",
       "predicted  43.93  2.59  28.00  2.65  5.89  3.65"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show results\n",
    "df = pd.DataFrame([target_dim, output_dim], index=['true', 'predicted'], \n",
    "                  columns=shape_params)\n",
    "df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "# generate polygons\n",
    "true_o, true_i = shape_func(*target_dim.squeeze())\n",
    "pred_o, pred_i = shape_func(*output_dim.squeeze())\n",
    "\n",
    "\n",
    "for outer in true_o:\n",
    "    mppoly = plt.Polygon(outer, ec=\"k\", ls='--', fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "for inner in true_i:\n",
    "    mppoly = plt.Polygon(inner, ec=\"k\", ls='--', fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "    \n",
    "for outer in pred_o:\n",
    "    mppoly = plt.Polygon(outer, ec=\"r\", fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "for inner in pred_i:\n",
    "    mppoly = plt.Polygon(inner, ec=\"r\", fill=False, linewidth=1)\n",
    "    ax.add_patch(mppoly)\n",
    "\n",
    "ax.autoscale(tight=False)\n",
    "ax.set_aspect(\"equal\")\n",
    "#ax.axis(\"off\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate: Compute IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Loop: Input polygon vertices, create image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be completed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
